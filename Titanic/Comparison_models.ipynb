{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison of models Titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import category_encoders as ce\n",
    "\n",
    "# Load a sheet into a DataFrame by its name\n",
    "df = pd.read_excel('files/titanic3.xlsx')\n",
    "\n",
    "# We are going to change these outliers to the mean price that has been paid by the other passengers, we could do this by simply changing\n",
    "# the fare price of these passengers but let's use the technique that would be used when there are more than a few outliers\n",
    "# We use the outlier detection and removal technique\n",
    "\n",
    "# Calculate the IQR (InterQuartile Range) for the fare column\n",
    "Q1 = df['fare'].quantile(0.25)\n",
    "Q3 = df['fare'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Define lower and upper bound for outliers, (sidenote, normally the multiplier used to calculate the lower and upper bound is around 1.5\n",
    "# but this would cause the identification of normal data as outliers resulting in a lot of good data to be lost because it is flagged as an\n",
    "# outlier. This is why we use such a high multiplier value.\n",
    "lower_bound = Q1 - 10 * IQR\n",
    "upper_bound = Q3 + 10 * IQR\n",
    "\n",
    "# Filter the data to exclude outliers\n",
    "df = df[(df['fare'] >= lower_bound) & (df['fare'] <= upper_bound)]\n",
    "\n",
    "df['firstname']=df['name'].str.split(r'[,.]', expand=True)[2]\n",
    "df['title']=df['name'].str.split(r'[,.]', expand=True)[1]\n",
    "df['lastname']=df['name'].str.split(r'[,.]', expand=True)[0]\n",
    "\n",
    "df.drop('name', axis = 1, inplace = True)\n",
    "\n",
    "normalized_titles = {\n",
    "    \"Capt\":       \"Officer\",\n",
    "    \"Col\":        \"Officer\",\n",
    "    \"Major\":      \"Officer\",\n",
    "    \"Jonkheer\":   \"Royal\",\n",
    "    \"Don\":        \"Royal\",\n",
    "    \"Sir\" :       \"Royal\",\n",
    "    \"Dr\":         \"Officer\",\n",
    "    \"Rev\":        \"Officer\",\n",
    "    \"the Countess\":\"Royal\",\n",
    "    \"Dona\":       \"Royal\",\n",
    "    \"Mme\":        \"Mrs\",\n",
    "    \"Mlle\":       \"Miss\",\n",
    "    \"Ms\":         \"Mrs\",\n",
    "    \"Mr\" :        \"Mr\",\n",
    "    \"Mrs\" :       \"Mrs\",\n",
    "    \"Miss\" :      \"Miss\",\n",
    "    \"Master\" :    \"Master\",\n",
    "    \"Lady\" :      \"Royal\"\n",
    "}\n",
    "# Strip leading and trailing spaces from the 'title' column\n",
    "df['title'] = df['title'].str.strip()\n",
    "\n",
    "# Now, apply the mapping to change original values to new values\n",
    "df['title'] = df['title'].map(normalized_titles)\n",
    "\n",
    "# Calculate the mean age for non-null values\n",
    "mean_age = df['age'].mean()\n",
    "\n",
    "# Calculate the standard deviation of the age column, which will be used to generate random but believable age values\n",
    "std_age = df['age'].std()\n",
    "\n",
    "# Create a mask to identify rows with \"Master\" or \"Miss\" in the \"title\" column\n",
    "master_miss_mask = (df['title'] == 'Master') | (df['title'] == 'Miss')\n",
    "\n",
    "# Generate random values for rows with \"Master\" or \"Miss\" based on a different standard deviation\n",
    "random_values_master_miss = np.random.normal(loc=0, scale=std_age * 0.5, size=master_miss_mask.sum())\n",
    "\n",
    "# Shift the distribution to have the same mean as the original data\n",
    "added_values_master_miss = random_values_master_miss + mean_age\n",
    "\n",
    "# Update the 'age' column for rows with \"Master\" or \"Miss\" individually\n",
    "master_miss_indices = df.index[master_miss_mask]\n",
    "for i, index in enumerate(master_miss_indices):\n",
    "    # Ensure that the age does not exceed 18\n",
    "    age = min(added_values_master_miss[i], 18)\n",
    "    df.loc[index, 'age'] = age\n",
    "\n",
    "# For all other missing values, use the previously calculated random values\n",
    "random_values = np.random.normal(loc=0, scale=std_age, size=df['age'].isna().sum())\n",
    "added_values = random_values + mean_age\n",
    "\n",
    "# Update the 'age' column for all other missing values individually\n",
    "other_indices = df.index[~master_miss_mask & df['age'].isna()]\n",
    "for i, index in enumerate(other_indices):\n",
    "    df.loc[index, 'age'] = added_values[i]\n",
    "\n",
    "# Change the datatype of the age column from float to int\n",
    "df['age'] = df['age'].astype(int)\n",
    "\n",
    "\n",
    "df['cabin'].fillna(0, inplace=True)\n",
    "\n",
    "# Replace non-null values with 1 without having problems because there are non-numerical values\n",
    "df['cabin'] = df['cabin'].apply(lambda x: 1 if x != 0 else x)\n",
    "\n",
    "# There are 2 null values in the embarked column, because it is such a small amount of data we simply change it to the value 'Q'\n",
    "# which stands for Queenstown\n",
    "df['embarked'] = df['embarked'].replace(np.nan, 'Q')\n",
    "\n",
    "\n",
    "df['boat'].fillna(0, inplace=True)\n",
    "\n",
    "# Replace non-null values with 1 without having problems because there are non-numerical values\n",
    "df['boat'] = df['boat'].apply(lambda x: 1 if x != 0 else x)\n",
    "\n",
    "\n",
    "df['body'].fillna(0, inplace=True)\n",
    "\n",
    "# Replace non-null values with 1 without having problems because there are non-numerical values\n",
    "df['body'] = df['body'].apply(lambda x: 1 if x != 0 else x)\n",
    "# We change the datatype from float to int\n",
    "df['body'] = df['body'].astype(int)\n",
    "\n",
    "df.drop('home.dest', axis = 1, inplace = True)\n",
    "\n",
    "df['survived'] = df['survived'].astype(bool)\n",
    "df['boat'] = df['boat'].astype(bool)\n",
    "df['body'] = df['body'].astype(bool)\n",
    "df['embarked'] = str(df['embarked'])\n",
    "\n",
    "encoder = ce.OrdinalEncoder(cols=['sex'])\n",
    "df_encoded = encoder.fit_transform(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wouter model Pycaret Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_70e6a_row9_col1 {\n",
       "  background-color: lightgreen;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_70e6a\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_70e6a_level0_col0\" class=\"col_heading level0 col0\" >Description</th>\n",
       "      <th id=\"T_70e6a_level0_col1\" class=\"col_heading level0 col1\" >Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_70e6a_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_70e6a_row0_col0\" class=\"data row0 col0\" >Session id</td>\n",
       "      <td id=\"T_70e6a_row0_col1\" class=\"data row0 col1\" >123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_70e6a_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_70e6a_row1_col0\" class=\"data row1 col0\" >Target</td>\n",
       "      <td id=\"T_70e6a_row1_col1\" class=\"data row1 col1\" >survived</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_70e6a_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_70e6a_row2_col0\" class=\"data row2 col0\" >Target type</td>\n",
       "      <td id=\"T_70e6a_row2_col1\" class=\"data row2 col1\" >Binary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_70e6a_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_70e6a_row3_col0\" class=\"data row3 col0\" >Original data shape</td>\n",
       "      <td id=\"T_70e6a_row3_col1\" class=\"data row3 col1\" >(1304, 15)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_70e6a_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_70e6a_row4_col0\" class=\"data row4 col0\" >Transformed data shape</td>\n",
       "      <td id=\"T_70e6a_row4_col1\" class=\"data row4 col1\" >(1304, 20)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_70e6a_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_70e6a_row5_col0\" class=\"data row5 col0\" >Transformed train set shape</td>\n",
       "      <td id=\"T_70e6a_row5_col1\" class=\"data row5 col1\" >(912, 20)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_70e6a_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_70e6a_row6_col0\" class=\"data row6 col0\" >Transformed test set shape</td>\n",
       "      <td id=\"T_70e6a_row6_col1\" class=\"data row6 col1\" >(392, 20)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_70e6a_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_70e6a_row7_col0\" class=\"data row7 col0\" >Numeric features</td>\n",
       "      <td id=\"T_70e6a_row7_col1\" class=\"data row7 col1\" >7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_70e6a_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_70e6a_row8_col0\" class=\"data row8 col0\" >Categorical features</td>\n",
       "      <td id=\"T_70e6a_row8_col1\" class=\"data row8 col1\" >5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_70e6a_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_70e6a_row9_col0\" class=\"data row9 col0\" >Preprocess</td>\n",
       "      <td id=\"T_70e6a_row9_col1\" class=\"data row9 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_70e6a_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_70e6a_row10_col0\" class=\"data row10 col0\" >Imputation type</td>\n",
       "      <td id=\"T_70e6a_row10_col1\" class=\"data row10 col1\" >simple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_70e6a_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_70e6a_row11_col0\" class=\"data row11 col0\" >Numeric imputation</td>\n",
       "      <td id=\"T_70e6a_row11_col1\" class=\"data row11 col1\" >mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_70e6a_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_70e6a_row12_col0\" class=\"data row12 col0\" >Categorical imputation</td>\n",
       "      <td id=\"T_70e6a_row12_col1\" class=\"data row12 col1\" >mode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_70e6a_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_70e6a_row13_col0\" class=\"data row13 col0\" >Maximum one-hot encoding</td>\n",
       "      <td id=\"T_70e6a_row13_col1\" class=\"data row13 col1\" >25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_70e6a_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_70e6a_row14_col0\" class=\"data row14 col0\" >Encoding method</td>\n",
       "      <td id=\"T_70e6a_row14_col1\" class=\"data row14 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_70e6a_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_70e6a_row15_col0\" class=\"data row15 col0\" >Fold Generator</td>\n",
       "      <td id=\"T_70e6a_row15_col1\" class=\"data row15 col1\" >StratifiedKFold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_70e6a_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_70e6a_row16_col0\" class=\"data row16 col0\" >Fold Number</td>\n",
       "      <td id=\"T_70e6a_row16_col1\" class=\"data row16 col1\" >10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_70e6a_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "      <td id=\"T_70e6a_row17_col0\" class=\"data row17 col0\" >CPU Jobs</td>\n",
       "      <td id=\"T_70e6a_row17_col1\" class=\"data row17 col1\" >-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_70e6a_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "      <td id=\"T_70e6a_row18_col0\" class=\"data row18 col0\" >Use GPU</td>\n",
       "      <td id=\"T_70e6a_row18_col1\" class=\"data row18 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_70e6a_level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
       "      <td id=\"T_70e6a_row19_col0\" class=\"data row19 col0\" >Log Experiment</td>\n",
       "      <td id=\"T_70e6a_row19_col1\" class=\"data row19 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_70e6a_level0_row20\" class=\"row_heading level0 row20\" >20</th>\n",
       "      <td id=\"T_70e6a_row20_col0\" class=\"data row20 col0\" >Experiment Name</td>\n",
       "      <td id=\"T_70e6a_row20_col1\" class=\"data row20 col1\" >clf-default-name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_70e6a_level0_row21\" class=\"row_heading level0 row21\" >21</th>\n",
       "      <td id=\"T_70e6a_row21_col0\" class=\"data row21 col0\" >USI</td>\n",
       "      <td id=\"T_70e6a_row21_col1\" class=\"data row21 col1\" >ae03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1ea20897580>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformation Pipeline and Model Successfully Loaded\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_bfc98\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_bfc98_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_bfc98_level0_col1\" class=\"col_heading level0 col1\" >Accuracy</th>\n",
       "      <th id=\"T_bfc98_level0_col2\" class=\"col_heading level0 col2\" >AUC</th>\n",
       "      <th id=\"T_bfc98_level0_col3\" class=\"col_heading level0 col3\" >Recall</th>\n",
       "      <th id=\"T_bfc98_level0_col4\" class=\"col_heading level0 col4\" >Prec.</th>\n",
       "      <th id=\"T_bfc98_level0_col5\" class=\"col_heading level0 col5\" >F1</th>\n",
       "      <th id=\"T_bfc98_level0_col6\" class=\"col_heading level0 col6\" >Kappa</th>\n",
       "      <th id=\"T_bfc98_level0_col7\" class=\"col_heading level0 col7\" >MCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_bfc98_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_bfc98_row0_col0\" class=\"data row0 col0\" >Logistic Regression</td>\n",
       "      <td id=\"T_bfc98_row0_col1\" class=\"data row0 col1\" >0.9755</td>\n",
       "      <td id=\"T_bfc98_row0_col2\" class=\"data row0 col2\" >0.9970</td>\n",
       "      <td id=\"T_bfc98_row0_col3\" class=\"data row0 col3\" >0.9536</td>\n",
       "      <td id=\"T_bfc98_row0_col4\" class=\"data row0 col4\" >0.9813</td>\n",
       "      <td id=\"T_bfc98_row0_col5\" class=\"data row0 col5\" >0.9673</td>\n",
       "      <td id=\"T_bfc98_row0_col6\" class=\"data row0 col6\" >0.9477</td>\n",
       "      <td id=\"T_bfc98_row0_col7\" class=\"data row0 col7\" >0.9479</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1ea1c0c48b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Prec.</th>\n",
       "      <th>F1</th>\n",
       "      <th>Kappa</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.9755</td>\n",
       "      <td>0.997</td>\n",
       "      <td>0.9536</td>\n",
       "      <td>0.9813</td>\n",
       "      <td>0.9673</td>\n",
       "      <td>0.9477</td>\n",
       "      <td>0.9479</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Accuracy    AUC  Recall   Prec.      F1   Kappa  \\\n",
       "0  Logistic Regression    0.9755  0.997  0.9536  0.9813  0.9673  0.9477   \n",
       "\n",
       "      MCC  \n",
       "0  0.9479  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pycaret.classification import *\n",
    "s = setup(df_encoded, target = 'survived', session_id = 123)\n",
    "loaded_Pycaret_model = load_model('files/titanic_pycaret_model')\n",
    "predict_model(loaded_Pycaret_model, data=df_encoded)\n",
    "measuresLogisticRegression = pull()\n",
    "measuresLogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_de933_row9_col1 {\n",
       "  background-color: lightgreen;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_de933\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_de933_level0_col0\" class=\"col_heading level0 col0\" >Description</th>\n",
       "      <th id=\"T_de933_level0_col1\" class=\"col_heading level0 col1\" >Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_de933_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_de933_row0_col0\" class=\"data row0 col0\" >Session id</td>\n",
       "      <td id=\"T_de933_row0_col1\" class=\"data row0 col1\" >123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_de933_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_de933_row1_col0\" class=\"data row1 col0\" >Target</td>\n",
       "      <td id=\"T_de933_row1_col1\" class=\"data row1 col1\" >survived</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_de933_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_de933_row2_col0\" class=\"data row2 col0\" >Target type</td>\n",
       "      <td id=\"T_de933_row2_col1\" class=\"data row2 col1\" >Binary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_de933_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_de933_row3_col0\" class=\"data row3 col0\" >Original data shape</td>\n",
       "      <td id=\"T_de933_row3_col1\" class=\"data row3 col1\" >(1304, 15)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_de933_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_de933_row4_col0\" class=\"data row4 col0\" >Transformed data shape</td>\n",
       "      <td id=\"T_de933_row4_col1\" class=\"data row4 col1\" >(1304, 20)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_de933_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_de933_row5_col0\" class=\"data row5 col0\" >Transformed train set shape</td>\n",
       "      <td id=\"T_de933_row5_col1\" class=\"data row5 col1\" >(912, 20)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_de933_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_de933_row6_col0\" class=\"data row6 col0\" >Transformed test set shape</td>\n",
       "      <td id=\"T_de933_row6_col1\" class=\"data row6 col1\" >(392, 20)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_de933_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_de933_row7_col0\" class=\"data row7 col0\" >Numeric features</td>\n",
       "      <td id=\"T_de933_row7_col1\" class=\"data row7 col1\" >7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_de933_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_de933_row8_col0\" class=\"data row8 col0\" >Categorical features</td>\n",
       "      <td id=\"T_de933_row8_col1\" class=\"data row8 col1\" >5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_de933_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_de933_row9_col0\" class=\"data row9 col0\" >Preprocess</td>\n",
       "      <td id=\"T_de933_row9_col1\" class=\"data row9 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_de933_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_de933_row10_col0\" class=\"data row10 col0\" >Imputation type</td>\n",
       "      <td id=\"T_de933_row10_col1\" class=\"data row10 col1\" >simple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_de933_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_de933_row11_col0\" class=\"data row11 col0\" >Numeric imputation</td>\n",
       "      <td id=\"T_de933_row11_col1\" class=\"data row11 col1\" >mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_de933_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_de933_row12_col0\" class=\"data row12 col0\" >Categorical imputation</td>\n",
       "      <td id=\"T_de933_row12_col1\" class=\"data row12 col1\" >mode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_de933_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_de933_row13_col0\" class=\"data row13 col0\" >Maximum one-hot encoding</td>\n",
       "      <td id=\"T_de933_row13_col1\" class=\"data row13 col1\" >25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_de933_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_de933_row14_col0\" class=\"data row14 col0\" >Encoding method</td>\n",
       "      <td id=\"T_de933_row14_col1\" class=\"data row14 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_de933_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_de933_row15_col0\" class=\"data row15 col0\" >Fold Generator</td>\n",
       "      <td id=\"T_de933_row15_col1\" class=\"data row15 col1\" >StratifiedKFold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_de933_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_de933_row16_col0\" class=\"data row16 col0\" >Fold Number</td>\n",
       "      <td id=\"T_de933_row16_col1\" class=\"data row16 col1\" >10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_de933_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "      <td id=\"T_de933_row17_col0\" class=\"data row17 col0\" >CPU Jobs</td>\n",
       "      <td id=\"T_de933_row17_col1\" class=\"data row17 col1\" >-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_de933_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "      <td id=\"T_de933_row18_col0\" class=\"data row18 col0\" >Use GPU</td>\n",
       "      <td id=\"T_de933_row18_col1\" class=\"data row18 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_de933_level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
       "      <td id=\"T_de933_row19_col0\" class=\"data row19 col0\" >Log Experiment</td>\n",
       "      <td id=\"T_de933_row19_col1\" class=\"data row19 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_de933_level0_row20\" class=\"row_heading level0 row20\" >20</th>\n",
       "      <td id=\"T_de933_row20_col0\" class=\"data row20 col0\" >Experiment Name</td>\n",
       "      <td id=\"T_de933_row20_col1\" class=\"data row20 col1\" >clf-default-name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_de933_level0_row21\" class=\"row_heading level0 row21\" >21</th>\n",
       "      <td id=\"T_de933_row21_col0\" class=\"data row21 col0\" >USI</td>\n",
       "      <td id=\"T_de933_row21_col1\" class=\"data row21 col1\" >a5d7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1ea21443730>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformation Pipeline and Model Successfully Loaded\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_44b0b\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_44b0b_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_44b0b_level0_col1\" class=\"col_heading level0 col1\" >Accuracy</th>\n",
       "      <th id=\"T_44b0b_level0_col2\" class=\"col_heading level0 col2\" >AUC</th>\n",
       "      <th id=\"T_44b0b_level0_col3\" class=\"col_heading level0 col3\" >Recall</th>\n",
       "      <th id=\"T_44b0b_level0_col4\" class=\"col_heading level0 col4\" >Prec.</th>\n",
       "      <th id=\"T_44b0b_level0_col5\" class=\"col_heading level0 col5\" >F1</th>\n",
       "      <th id=\"T_44b0b_level0_col6\" class=\"col_heading level0 col6\" >Kappa</th>\n",
       "      <th id=\"T_44b0b_level0_col7\" class=\"col_heading level0 col7\" >MCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_44b0b_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_44b0b_row0_col0\" class=\"data row0 col0\" >Logistic Regression</td>\n",
       "      <td id=\"T_44b0b_row0_col1\" class=\"data row0 col1\" >0.9218</td>\n",
       "      <td id=\"T_44b0b_row0_col2\" class=\"data row0 col2\" >0.9727</td>\n",
       "      <td id=\"T_44b0b_row0_col3\" class=\"data row0 col3\" >0.8407</td>\n",
       "      <td id=\"T_44b0b_row0_col4\" class=\"data row0 col4\" >0.9477</td>\n",
       "      <td id=\"T_44b0b_row0_col5\" class=\"data row0 col5\" >0.8910</td>\n",
       "      <td id=\"T_44b0b_row0_col6\" class=\"data row0 col6\" >0.8304</td>\n",
       "      <td id=\"T_44b0b_row0_col7\" class=\"data row0 col7\" >0.8340</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1ea210d1870>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Prec.</th>\n",
       "      <th>F1</th>\n",
       "      <th>Kappa</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.9218</td>\n",
       "      <td>0.9727</td>\n",
       "      <td>0.8407</td>\n",
       "      <td>0.9477</td>\n",
       "      <td>0.891</td>\n",
       "      <td>0.8304</td>\n",
       "      <td>0.834</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Accuracy     AUC  Recall   Prec.     F1   Kappa    MCC\n",
       "0  Logistic Regression    0.9218  0.9727  0.8407  0.9477  0.891  0.8304  0.834"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = setup(df_encoded, target = 'survived', session_id = 123)\n",
    "\n",
    "\n",
    "loaded_Pycaret_model_excluded = load_model('files/titanic_exluded_pycaret_model')\n",
    "predict_model(loaded_Pycaret_model_excluded, data=df_encoded)\n",
    "measuresLogisticRegression_excluded = pull()\n",
    "measuresLogisticRegression_excluded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kieran model GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import pandas as pd\n",
    "features = ['pclass','sex','age','sibsp','parch','fare','cabin','boat','body','ticket', 'embarked','firstname','title','lastname']\n",
    "x = df_encoded[features]\n",
    "y = df_encoded['survived']\n",
    "\n",
    "X = pd.get_dummies(x, columns=['ticket', 'embarked','firstname','title','lastname'], drop_first=True)\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_no_boat = ['pclass','sex','age','sibsp','parch','fare','cabin','ticket', 'embarked','firstname','title','lastname']\n",
    "x_no_boat = df_encoded[features_no_boat]\n",
    "y_no_boat = df_encoded['survived']\n",
    "\n",
    "X_no_boat = pd.get_dummies(x_no_boat, columns=['ticket', 'embarked','firstname','title','lastname'], drop_first=True)\n",
    "\n",
    "#Split into training and test set\n",
    "x_train_no_boat, x_test_no_boat, y_train_no_boat, y_test_no_boat = train_test_split(X_no_boat, y_no_boat, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion=&#x27;friedman_mse&#x27;,\n",
       "                          init=None, learning_rate=0.1, loss=&#x27;squared_error&#x27;,\n",
       "                          max_depth=3, max_features=None, max_leaf_nodes=None,\n",
       "                          min_impurity_decrease=0.0, min_samples_leaf=1,\n",
       "                          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                          n_estimators=100, n_iter_no_change=None,\n",
       "                          random_state=0, subsample=1.0, tol=0.0001,\n",
       "                          validation_fraction=0.1, verbose=0, warm_start=False)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion=&#x27;friedman_mse&#x27;,\n",
       "                          init=None, learning_rate=0.1, loss=&#x27;squared_error&#x27;,\n",
       "                          max_depth=3, max_features=None, max_leaf_nodes=None,\n",
       "                          min_impurity_decrease=0.0, min_samples_leaf=1,\n",
       "                          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                          n_estimators=100, n_iter_no_change=None,\n",
       "                          random_state=0, subsample=1.0, tol=0.0001,\n",
       "                          validation_fraction=0.1, verbose=0, warm_start=False)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
       "                          init=None, learning_rate=0.1, loss='squared_error',\n",
       "                          max_depth=3, max_features=None, max_leaf_nodes=None,\n",
       "                          min_impurity_decrease=0.0, min_samples_leaf=1,\n",
       "                          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                          n_estimators=100, n_iter_no_change=None,\n",
       "                          random_state=0, subsample=1.0, tol=0.0001,\n",
       "                          validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "# Load the model from disk\n",
    "filename = 'files/titanic_chosen_model_no_boat.sav'\n",
    "GradientBoostRegressor_model_no_boat = pickle.load(open(filename, 'rb'))\n",
    "GradientBoostRegressor_model_no_boat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion=&#x27;friedman_mse&#x27;,\n",
       "                          init=None, learning_rate=0.1, loss=&#x27;squared_error&#x27;,\n",
       "                          max_depth=3, max_features=None, max_leaf_nodes=None,\n",
       "                          min_impurity_decrease=0.0, min_samples_leaf=1,\n",
       "                          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                          n_estimators=100, n_iter_no_change=None,\n",
       "                          random_state=0, subsample=1.0, tol=0.0001,\n",
       "                          validation_fraction=0.1, verbose=0, warm_start=False)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion=&#x27;friedman_mse&#x27;,\n",
       "                          init=None, learning_rate=0.1, loss=&#x27;squared_error&#x27;,\n",
       "                          max_depth=3, max_features=None, max_leaf_nodes=None,\n",
       "                          min_impurity_decrease=0.0, min_samples_leaf=1,\n",
       "                          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                          n_estimators=100, n_iter_no_change=None,\n",
       "                          random_state=0, subsample=1.0, tol=0.0001,\n",
       "                          validation_fraction=0.1, verbose=0, warm_start=False)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
       "                          init=None, learning_rate=0.1, loss='squared_error',\n",
       "                          max_depth=3, max_features=None, max_leaf_nodes=None,\n",
       "                          min_impurity_decrease=0.0, min_samples_leaf=1,\n",
       "                          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                          n_estimators=100, n_iter_no_change=None,\n",
       "                          random_state=0, subsample=1.0, tol=0.0001,\n",
       "                          validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the model from disk\n",
    "filename = 'files/titanic_chosen_model.sav'\n",
    "GradientBoostRegressor_model = pickle.load(open(filename, 'rb'))\n",
    "GradientBoostRegressor_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_prob = GradientBoostRegressor_model.predict(x_test)\n",
    "y_pred_prob_no_boat = GradientBoostRegressor_model_no_boat.predict(x_test_no_boat)\n",
    "\n",
    "threshold = 0.5\n",
    "y_pred = (y_pred_prob > threshold).astype(int)\n",
    "y_pred_no_boat = (y_pred_prob_no_boat > threshold).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Laurens model AWS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy\n",
    "Accuracy is used to measure how well a model correctly predicts the class labels of the instances in a dataset.\n",
    "Here we can see that the GradienBoostRegressor scores better with column boat & body included but scores less when they are exluded.\n",
    "Probably the reason why Pycaret couldn't find a model that scores better than the GradientBoostRegressor is because it has a limited list of models. So it is pretty cool Kieran found a model that beats Pycaret.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wouter model Pycaret LogisticRegression:  0    0.9755\n",
      "Name: Accuracy, dtype: float64\n",
      "Wouter model Pycaret LogisticRegression no boat:  0    0.9218\n",
      "Name: Accuracy, dtype: float64\n",
      "\n",
      "Kieran model GradientBoostRegressor:  0.9846743295019157\n",
      "Kieran model GradientBoostRegressor no boat:  0.8314176245210728\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Wouter model Pycaret LogisticRegression: \", measuresLogisticRegression[\"Accuracy\"])\n",
    "print(\"Wouter model Pycaret LogisticRegression no boat: \", measuresLogisticRegression_excluded[\"Accuracy\"])\n",
    "print()\n",
    "GradientBoostRegressor_Accuracy = accuracy_score(y_test, y_pred)\n",
    "GradientBoostRegressor_Accuracy_no_boat = accuracy_score(y_test_no_boat, y_pred_no_boat)\n",
    "\n",
    "print(\"Kieran model GradientBoostRegressor: \", GradientBoostRegressor_Accuracy)\n",
    "print(\"Kieran model GradientBoostRegressor no boat: \", GradientBoostRegressor_Accuracy_no_boat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precision\n",
    "Precision is used to measure the accuracy of positive predictions made by a model. It answers the question, out of all instances predicted as positive, how many were correctly predicted?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wouter model Pycaret LogisticRegression:  0    0.9813\n",
      "Name: Prec., dtype: float64\n",
      "Wouter model Pycaret LogisticRegression no boat:  0    0.9477\n",
      "Name: Prec., dtype: float64\n",
      "\n",
      "Kieran model GradientBoostRegressor:  0.9891304347826086\n",
      "Kieran model GradientBoostRegressor no boat:  0.8205128205128205\n"
     ]
    }
   ],
   "source": [
    "print(\"Wouter model Pycaret LogisticRegression: \", measuresLogisticRegression[\"Prec.\"])\n",
    "print(\"Wouter model Pycaret LogisticRegression no boat: \", measuresLogisticRegression_excluded[\"Prec.\"])\n",
    "print()\n",
    "\n",
    "GradientBoostRegressor_precision = precision_score(y_test, y_pred)\n",
    "GradientBoostRegressor_precision_no_boat = precision_score(y_test_no_boat, y_pred_no_boat)\n",
    "\n",
    "print(\"Kieran model GradientBoostRegressor: \",GradientBoostRegressor_precision)\n",
    "print(\"Kieran model GradientBoostRegressor no boat: \", GradientBoostRegressor_precision_no_boat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recall\n",
    "Recall which is also known as Sensitivity or True Positive Rate is used to measure a model's ability to correctly  identify all positive instances within a dataset. It answers the question, out of all ACTUAL positive instances, how many were correctly predicted as positive by the model?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wouter model Pycaret LogisticRegression:  0    0.9536\n",
      "Name: Recall, dtype: float64\n",
      "Wouter model Pycaret LogisticRegression no boat:  0    0.8407\n",
      "Name: Recall, dtype: float64\n",
      "\n",
      "Kieran model GradientBoostRegressor:  0.9680851063829787\n",
      "Kieran model GradientBoostRegressor no boat:  0.6808510638297872\n"
     ]
    }
   ],
   "source": [
    "print(\"Wouter model Pycaret LogisticRegression: \", measuresLogisticRegression[\"Recall\"])\n",
    "print(\"Wouter model Pycaret LogisticRegression no boat: \", measuresLogisticRegression_excluded[\"Recall\"])\n",
    "print()\n",
    "\n",
    "GradientBoostRegressor_recall = recall_score(y_test, y_pred)\n",
    "GradientBoostRegressor_recall_no_boat = recall_score(y_test_no_boat, y_pred_no_boat)\n",
    "\n",
    "print(\"Kieran model GradientBoostRegressor: \",GradientBoostRegressor_recall)\n",
    "print(\"Kieran model GradientBoostRegressor no boat: \", GradientBoostRegressor_recall_no_boat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC AUC\n",
    "ROC AUC is used to measures how well the model can distinguish between positive and negative. A higher ROC AUC score would mean that the model is better at this and lower means it is bad. A score of 0.5 would mean truly random and would mean that the model is no better than random guessing and with 1.0 it is perfect at distinguishing between the classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wouter model Pycaret LogisticRegression:  0    0.997\n",
      "Name: AUC, dtype: float64\n",
      "Wouter model Pycaret LogisticRegression no boat:  0    0.9727\n",
      "Name: AUC, dtype: float64\n",
      "\n",
      "Kieran model GradientBoostRegressor:  0.9810485412154414\n",
      "Kieran model GradientBoostRegressor no boat:  0.798509364250223\n"
     ]
    }
   ],
   "source": [
    "print(\"Wouter model Pycaret LogisticRegression: \", measuresLogisticRegression[\"AUC\"])\n",
    "print(\"Wouter model Pycaret LogisticRegression no boat: \", measuresLogisticRegression_excluded[\"AUC\"])\n",
    "print()\n",
    "\n",
    "GradientBoostRegressor_roc_auc = roc_auc_score(y_test, y_pred)\n",
    "GradientBoostRegressor_roc_auc_no_boat = roc_auc_score(y_test_no_boat, y_pred_no_boat)\n",
    "\n",
    "print(\"Kieran model GradientBoostRegressor: \",GradientBoostRegressor_roc_auc)\n",
    "print(\"Kieran model GradientBoostRegressor no boat: \", GradientBoostRegressor_roc_auc_no_boat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conlusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the Pycaret LogisticRegression model scores less then GradientBoostRegressor model on the trained model with boat and body columns. Except on the last metric ROC AUC the Pycaret LogisticRegression model scores better. This means that in general the GradientBoostRegressor model is better at differentiating between the four different classes TP, FP, TN, FN. When it comes to differentiating between just positive and negative (ROC AUC) we see that the Pycaret LogisticRegressor model is better.\n",
    "\n",
    "\n",
    "When we look at the models excluding the columns boat and body, we see that the Pycaret LogisticRegression model scores better on all the metrics. When we look at the GradientBoostRegressor model not using the boat and body column we see a clear drop in perfomance. This means that the GradientBoostRegressor model depends on the columns boat and body and therefore drops in performance when exlcuding these columns. Conversely the Pycaret LogisticRegression model remains kind of the same when dropping these two columns. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
