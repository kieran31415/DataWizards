{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import category_encoders as ce\n",
    "import missingno\n",
    "\n",
    "# Load a sheet into a DataFrame by its name\n",
    "df = pd.read_excel('files/titanic3.xlsx')\n",
    "\n",
    "# We are going to change these outliers to the mean price that has been paid by the other passengers, we could do this by simply changing\n",
    "# the fare price of these passengers but let's use the technique that would be used when there are more than a few outliers\n",
    "# We use the outlier detection and removal technique\n",
    "\n",
    "# Calculate the IQR (InterQuartile Range) for the fare column\n",
    "Q1 = df['fare'].quantile(0.25)\n",
    "Q3 = df['fare'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Define lower and upper bound for outliers, (sidenote, normally the multiplier used to calculate the lower and upper bound is around 1.5\n",
    "# but this would cause the identification of normal data as outliers resulting in a lot of good data to be lost because it is flagged as an\n",
    "# outlier. This is why we use such a high multiplier value.\n",
    "lower_bound = Q1 - 10 * IQR\n",
    "upper_bound = Q3 + 10 * IQR\n",
    "\n",
    "# Filter the data to exclude outliers\n",
    "df = df[(df['fare'] >= lower_bound) & (df['fare'] <= upper_bound)]\n",
    "\n",
    "df['firstname']=df['name'].str.split(r'[,.]', expand=True)[2]\n",
    "df['title']=df['name'].str.split(r'[,.]', expand=True)[1]\n",
    "df['lastname']=df['name'].str.split(r'[,.]', expand=True)[0]\n",
    "\n",
    "df.drop('name', axis = 1, inplace = True)\n",
    "\n",
    "normalized_titles = {\n",
    "    \"Capt\":       \"Officer\",\n",
    "    \"Col\":        \"Officer\",\n",
    "    \"Major\":      \"Officer\",\n",
    "    \"Jonkheer\":   \"Royal\",\n",
    "    \"Don\":        \"Royal\",\n",
    "    \"Sir\" :       \"Royal\",\n",
    "    \"Dr\":         \"Officer\",\n",
    "    \"Rev\":        \"Officer\",\n",
    "    \"the Countess\":\"Royal\",\n",
    "    \"Dona\":       \"Royal\",\n",
    "    \"Mme\":        \"Mrs\",\n",
    "    \"Mlle\":       \"Miss\",\n",
    "    \"Ms\":         \"Mrs\",\n",
    "    \"Mr\" :        \"Mr\",\n",
    "    \"Mrs\" :       \"Mrs\",\n",
    "    \"Miss\" :      \"Miss\",\n",
    "    \"Master\" :    \"Master\",\n",
    "    \"Lady\" :      \"Royal\"\n",
    "}\n",
    "# Strip leading and trailing spaces from the 'title' column\n",
    "df['title'] = df['title'].str.strip()\n",
    "\n",
    "# Now, apply the mapping to change original values to new values\n",
    "df['title'] = df['title'].map(normalized_titles)\n",
    "\n",
    "# Calculate the mean age for non-null values\n",
    "mean_age = df['age'].mean()\n",
    "\n",
    "# Calculate the standard deviation of the age column, which will be used to generate random but believable age values\n",
    "std_age = df['age'].std()\n",
    "\n",
    "# Create a mask to identify rows with \"Master\" or \"Miss\" in the \"title\" column\n",
    "master_miss_mask = (df['title'] == 'Master') | (df['title'] == 'Miss')\n",
    "\n",
    "# Generate random values for rows with \"Master\" or \"Miss\" based on a different standard deviation\n",
    "random_values_master_miss = np.random.normal(loc=0, scale=std_age * 0.5, size=master_miss_mask.sum())\n",
    "\n",
    "# Shift the distribution to have the same mean as the original data\n",
    "added_values_master_miss = random_values_master_miss + mean_age\n",
    "\n",
    "# Update the 'age' column for rows with \"Master\" or \"Miss\" individually\n",
    "master_miss_indices = df.index[master_miss_mask]\n",
    "for i, index in enumerate(master_miss_indices):\n",
    "    # Ensure that the age does not exceed 18\n",
    "    age = min(added_values_master_miss[i], 18)\n",
    "    df.loc[index, 'age'] = age\n",
    "\n",
    "# For all other missing values, use the previously calculated random values\n",
    "random_values = np.random.normal(loc=0, scale=std_age, size=df['age'].isna().sum())\n",
    "added_values = random_values + mean_age\n",
    "\n",
    "# Update the 'age' column for all other missing values individually\n",
    "other_indices = df.index[~master_miss_mask & df['age'].isna()]\n",
    "for i, index in enumerate(other_indices):\n",
    "    df.loc[index, 'age'] = added_values[i]\n",
    "\n",
    "# Change the datatype of the age column from float to int\n",
    "df['age'] = df['age'].astype(int)\n",
    "\n",
    "\n",
    "df['cabin'].fillna(0, inplace=True)\n",
    "\n",
    "# Replace non-null values with 1 without having problems because there are non-numerical values\n",
    "df['cabin'] = df['cabin'].apply(lambda x: 1 if x != 0 else x)\n",
    "\n",
    "# There are 2 null values in the embarked column, because it is such a small amount of data we simply change it to the value 'Q'\n",
    "# which stands for Queenstown\n",
    "df['embarked'] = df['embarked'].replace(np.nan, 'Q')\n",
    "\n",
    "\n",
    "df['boat'].fillna(0, inplace=True)\n",
    "\n",
    "# Replace non-null values with 1 without having problems because there are non-numerical values\n",
    "df['boat'] = df['boat'].apply(lambda x: 1 if x != 0 else x)\n",
    "\n",
    "\n",
    "df['body'].fillna(0, inplace=True)\n",
    "\n",
    "# Replace non-null values with 1 without having problems because there are non-numerical values\n",
    "df['body'] = df['body'].apply(lambda x: 1 if x != 0 else x)\n",
    "# We change the datatype from float to int\n",
    "df['body'] = df['body'].astype(int)\n",
    "\n",
    "df.drop('home.dest', axis = 1, inplace = True)\n",
    "\n",
    "df['survived'] = df['survived'].astype(bool)\n",
    "df['boat'] = df['boat'].astype(bool)\n",
    "df['body'] = df['body'].astype(bool)\n",
    "df['embarked'] = str(df['embarked'])\n",
    "\n",
    "encoder = ce.OrdinalEncoder(cols=['sex'])\n",
    "df_encoded = encoder.fit_transform(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self chosen model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting Regressor\n",
    "\n",
    "I think that Gradient Boosting Regressor is a good technique to use for the Titanic dataset. They create an ensemble of weak learners to build a strong predictive model. These algorithms are known for their high predictive accuracy and can handle missing data and outliers gracefully."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With boat and body"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to do all of our imports so we can actually use the gradient boosting regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to define the features wich we want to use to make a prediction and the value we acctually want to predict. We place these in the variables x and y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['pclass','sex','age','sibsp','parch','fare','cabin','boat','body','ticket', 'embarked','firstname','title','lastname']\n",
    "x = df_encoded[features]\n",
    "y = df_encoded['survived']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The gradient boosting regressor can't handle text values. But in our dataset we do have text values. So with this line off code we are going to give all of these text values a number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.get_dummies(x, columns=['ticket', 'embarked','firstname','title','lastname'], drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we are going to split the dataset into a test and a training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to fit our model. We are using 100 estimators and random state 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GradientBoostingRegressor(random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingRegressor(random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GradientBoostingRegressor(random_state=0)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb_regressor = GradientBoostingRegressor(n_estimators=100, random_state=0)\n",
    "gb_regressor.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are going to use our test set to make a predictions using the model we just created. We save it in a temporary variable because our model returns float values, but we want to have boolean values (or 0 and 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_prob = gb_regressor.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To convert our float values to a boolean (or 0 and 1) we use the code below. everything that the model predicts as higher than 0.5 will be true and lower than 0.5 will be false."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.5\n",
    "y_pred = (y_pred_prob > threshold).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to print the actual values and the predicted values so we can see how well our model did."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Actual  Predicted\n",
      "1157   False          0\n",
      "978     True          1\n",
      "787    False          0\n",
      "1023    True          1\n",
      "316    False          0\n",
      "482     True          1\n",
      "5       True          1\n",
      "645     True          1\n",
      "420    False          0\n",
      "430     True          1\n",
      "286    False          0\n",
      "828    False          0\n",
      "31      True          1\n",
      "678    False          0\n",
      "970     True          1\n",
      "57      True          1\n",
      "715    False          0\n",
      "835    False          0\n",
      "911    False          0\n",
      "998    False          0\n",
      "946    False          0\n",
      "1025    True          1\n",
      "1244    True          1\n",
      "829    False          0\n",
      "805     True          1\n"
     ]
    }
   ],
   "source": [
    "result_df = pd.DataFrame({'Actual': y_test[:25], 'Predicted': y_pred[:25]})\n",
    "\n",
    "print(result_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Without Boat and Body"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have created another model but without the body and boat values. This is because these values will have a verry big impact on the result. For example if you don't have a boat the chances of survival are almost 0. So our model will almost always say that you won't survive if you don't have a boat. So with this model we can see hopw well it works without these almost certain values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['pclass','sex','age','sibsp','parch','fare','cabin','ticket', 'embarked','firstname','title','lastname']\n",
    "x = df_encoded[features]\n",
    "y = df_encoded['survived']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Actual  Predicted\n",
      "1157   False          0\n",
      "978     True          0\n",
      "787    False          0\n",
      "1023    True          1\n",
      "316    False          0\n",
      "482     True          1\n",
      "5       True          0\n",
      "645     True          0\n",
      "420    False          0\n",
      "430     True          1\n",
      "286    False          1\n",
      "828    False          0\n",
      "31      True          0\n",
      "678    False          0\n",
      "970     True          0\n",
      "57      True          1\n",
      "715    False          0\n",
      "835    False          0\n",
      "911    False          0\n",
      "998    False          0\n",
      "946    False          1\n",
      "1025    True          1\n",
      "1244    True          1\n",
      "829    False          0\n",
      "805     True          1\n"
     ]
    }
   ],
   "source": [
    "X = pd.get_dummies(x, columns=['ticket', 'embarked','firstname','title','lastname'], drop_first=True)\n",
    "\n",
    "#Split into training and test set\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "#Fit model\n",
    "gb_regressor = GradientBoostingRegressor(n_estimators=100, random_state=0)\n",
    "gb_regressor.fit(x_train, y_train)\n",
    "\n",
    "#Make predictions using test set\n",
    "y_pred_prob = gb_regressor.predict(x_test)\n",
    "\n",
    "#Convert float values to 0 or 1\n",
    "threshold = 0.5\n",
    "y_pred_no_boat = (y_pred_prob > threshold).astype(int)\n",
    "\n",
    "#Print actual and predicted values\n",
    "result_df = pd.DataFrame({'Actual': y_test[:25], 'Predicted': y_pred_no_boat[:25]})\n",
    "print(result_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's compare the models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see are the predictions of the model with the boat much better than the predictions without."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Actual  Predicted with boat  Predicted without boat\n",
      "1157   False                    0                       0\n",
      "978     True                    1                       0\n",
      "787    False                    0                       0\n",
      "1023    True                    1                       1\n",
      "316    False                    0                       0\n",
      "482     True                    1                       1\n",
      "5       True                    1                       0\n",
      "645     True                    1                       0\n",
      "420    False                    0                       0\n",
      "430     True                    1                       1\n",
      "286    False                    0                       1\n",
      "828    False                    0                       0\n",
      "31      True                    1                       0\n",
      "678    False                    0                       0\n",
      "970     True                    1                       0\n",
      "57      True                    1                       1\n",
      "715    False                    0                       0\n",
      "835    False                    0                       0\n",
      "911    False                    0                       0\n",
      "998    False                    0                       0\n",
      "946    False                    0                       1\n",
      "1025    True                    1                       1\n",
      "1244    True                    1                       1\n",
      "829    False                    0                       0\n",
      "805     True                    1                       1\n"
     ]
    }
   ],
   "source": [
    "result_df = pd.DataFrame({'Actual': y_test[:25],'Predicted with boat': y_pred[:25], 'Predicted without boat': y_pred_no_boat[:25]})\n",
    "print(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error with boat: 0.01532567049808429\n",
      "R-squared with boat: 0.933494712702255\n",
      "Mean Squared Error without boat: 0.16091954022988506\n",
      "R-squared without boat: 0.3016944833736783\n"
     ]
    }
   ],
   "source": [
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Mean Squared Error with boat: {mse}\")\n",
    "\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f\"R-squared with boat: {r2}\")\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred_no_boat)\n",
    "print(f\"Mean Squared Error without boat: {mse}\")\n",
    "\n",
    "r2 = r2_score(y_test, y_pred_no_boat)\n",
    "print(f\"R-squared without boat: {r2}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
